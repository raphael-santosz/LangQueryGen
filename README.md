# LangQueryGen

LangQueryGen is a modular AI-powered backend that transforms natural language questions into SQL queries using **Retrieval-Augmented Generation (RAG)** with **LangChain**, **Ollama** (local LLM like Mistral 7B), and **Flask**. The system also includes semantic validation of user input and a Node.js layer for interaction or interface.

---

## ðŸš€ Features

- ðŸ” **Natural Language to SQL** with LangChain and a local model (via Ollama)
- ðŸ§  **RAG pipeline** with FAISS and HuggingFace embeddings
- âœ… **Input validation agent** for filtering sensitive questions
- ðŸ› ï¸ **Modular Flask API** structure
- ðŸ§© **Node.js Integration** for frontend or orchestration
- ðŸ”’ **Fully local and secure** â€“ no external API calls

---

## ðŸ“ Project Structure

```
flask-server/
â”œâ”€â”€ app.py                 # Flask entry point
â”œâ”€â”€ routes/                # API routes (Blueprint)
â”œâ”€â”€ services/              # LangChain agents and logic
â”œâ”€â”€ models/                # Pydantic request/response models
â”œâ”€â”€ utils/                 # Auxiliary functions (e.g., query fixer)
â”œâ”€â”€ venv/                  # Python virtual environment
â”œâ”€â”€ package-lock.json      # Node.js dependencies
â””â”€â”€ ...
```

---

## ðŸ‘©â€ðŸ’» How to Run (Backend)

### 1. Clone the repo and create the virtual environment

```bash
git clone https://github.com/raphael-santosz/LangQueryGen.git
cd LangQueryGen/flask-server
python -m venv venv
source venv/bin/activate  # or .\venv\Scripts\activate on Windows
pip install -r requirements.txt
python app.py
```

---

## ðŸ‘©â€ðŸ’» How to Run (Frontend)

```bash
cd client
npm install
npm run dev
```

---

## ðŸ“† Requirements

- Python 3.10+
- Node.js 18+
- Ollama installed locally
- SQL Server or compatible DB
- Optional: FAISS, LangChain, HuggingFace embeddings

---

## âš™ï¸ Technologies

- ðŸ Flask + Pydantic
- ðŸ§  LangChain + Ollama + HuggingFace
- ðŸ«® SQLAlchemy
- ðŸŒ Node.js (for UI or extended API)
- ðŸ§  Mistral 7B / LLaMA3

---

## ðŸ›¡ï¸ Security

The validation agent checks whether the user input relates to sensitive topics like **salary** or **payment**, returning `"Blocked"` if found.\
All LLM interactions are **local and secure**, ensuring full data privacy.

---

## âœ¨ Authors

Developed by **Raphael Augusto Santos**  and **Rafael Azzolini**\
[GitHub](https://github.com/raphael-santosz)

---

## ðŸ—œï¸ General System Architecture

```mermaid
flowchart TD
    U[User submits question] --> IA1
    IA1 -->|Generates raw_query + result_data/tag| IA2
    IA2 -->|Validates/Refines query| IA3
    IA3 -->|Natural language response| U
```

---

## IA1 - Query Execution Flow

1. **IA1 generates `raw_query`** (using LLM + schema + examples)
2. **Executes the Query**: `conn.execute(raw_query).fetchall()`

```mermaid
flowchart TD
    A[IA1 generates raw_query] --> B{Executes the query}
    B -->|SQL Exception| C["SQL_ERROR_OCCURRED"]
    B -->|OK| D{Validate result format}
    D -->|Invalid| E["INVALID_RESULT_FORMAT"]
    D -->|Valid| F{Is result_data empty?}
    F -->|Yes| G["NO_RESULTS_FOUND"]
    F -->|No| H["Return raw_query and result_data"]
```

### Summary of possible IA1 outputs:

| Case                          | Output                                               |
| ----------------------------- | --------------------------------------------------- |
| SQL Exception                 | `"SQL_ERROR_OCCURRED"`                              |
| Invalid result                 | `"INVALID_RESULT_FORMAT"`                           |
| Query returned no results      | `"NO_RESULTS_FOUND"`                                |
| Query with valid results       | `{ "query": raw_query, "result_data": result_data }` |

---

## IA2 - Query Validation and Refinement Flow

1. **IA2 receives:** `user_question`, `generated_query`, `query_results`, `schema`

2. **Decides flow based on `query_results` tag:**

```mermaid
flowchart TD
    A[IA2 receives input] --> B{query_results is error tag?}
    B -->|SQL_ERROR_OCCURRED| C[IA2 tries to correct SQL error]
    B -->|INVALID_RESULT_FORMAT| D[IA2 regenerates query from scratch]
    B -->|NO_RESULTS_FOUND| E[IA2 validates semantically whether it was expected â†’ can accept empty result]
    B -->|Valid data| F[IA2 verifies if query correctly answers user_question]
```

### Notes:

- If `SQL_ERROR_OCCURRED` â†’ IA2 can fix things like quotes, joins, aliases, etc.
- If `INVALID_RESULT_FORMAT` â†’ IA2 assumes IA1 produced a bad query â†’ must regenerate.
- If `NO_RESULTS_FOUND` â†’ IA2 can accept result if it was semantically expected (e.g., non-existent employee).
- If `result_data` is valid â†’ IA2 performs semantic validation to verify if the query answers the question correctly.

---

## IA3 - Natural Language Response

```mermaid
flowchart TD
    IA2 --> IA3
    IA3 -->|Generates natural language response in the question's language| User
```

- IA3 always receives:

  - user_question
  - query_results
  - formatting_guide
  - answering_guide

- IA3:

  - If `NO_RESULTS_FOUND` or `SQL_ERROR_OCCURRED` â†’ returns a polite response.
  - If valid results â†’ responds with the results following the `answering_guide`.

---

## Final Notes

- The system is designed to be **modular, robust, and traceable**.
- The IA1 tags help IA2 avoid being confused by raw SQL errors or invalid results.
- The complete pipeline is controlled: IA1 â†’ IA2 â†’ IA3.

---

ðŸš€ **Ready for production or to be extended with other databases / models / UIs.**

---
